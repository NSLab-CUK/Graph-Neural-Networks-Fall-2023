{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e22c0024",
   "metadata": {},
   "source": [
    "### Outline:\n",
    "    Import Libraries and datasets from PyTorch Geometric\n",
    "    1. Extracting subgraphs from set of nodes\n",
    "    2. Extracting k_hop_subgraph from nodes\n",
    "    3. Dropping a random walk with a probability\n",
    "    4. MixHop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8423b58b",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ce94718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_geometric in c:\\users\\user\\anaconda3\\envs\\gnn11\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\envs\\gnn11\\lib\\site-packages (from torch_geometric) (4.66.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\gnn11\\lib\\site-packages (from torch_geometric) (1.24.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\envs\\gnn11\\lib\\site-packages (from torch_geometric) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\envs\\gnn11\\lib\\site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\gnn11\\lib\\site-packages (from torch_geometric) (2.31.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\user\\anaconda3\\envs\\gnn11\\lib\\site-packages (from torch_geometric) (3.1.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\envs\\gnn11\\lib\\site-packages (from torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\user\\anaconda3\\envs\\gnn11\\lib\\site-packages (from torch_geometric) (5.9.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\envs\\gnn11\\lib\\site-packages (from jinja2->torch_geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\gnn11\\lib\\site-packages (from requests->torch_geometric) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\gnn11\\lib\\site-packages (from requests->torch_geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\gnn11\\lib\\site-packages (from requests->torch_geometric) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\gnn11\\lib\\site-packages (from requests->torch_geometric) (2023.7.22)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\anaconda3\\envs\\gnn11\\lib\\site-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\envs\\gnn11\\lib\\site-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\gnn11\\lib\\site-packages (from tqdm->torch_geometric) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torchversion = torch.__version__\n",
    "\n",
    "# Install PyTorch Scatter, PyTorch Sparse, and PyTorch Geometric\n",
    "!pip install torch_geometric\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-{torchversion}.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-{torchversion}.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "\n",
    "# pip install wandb\n",
    "# pip install ogb\n",
    "\n",
    "# Numpy for matrices\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# Visualization\n",
    "import networkx as nx\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1501b05",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bf8636a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.24.1 in c:\\users\\user\\anaconda3\\envs\\gnn11\\lib\\site-packages (1.24.1)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "!pip install numpy==1.24.1\n",
    "# Import dataset from PyTorch Geometric\n",
    "dataset = Planetoid(root=\".\", name=\"cora\")\n",
    "\n",
    "data = dataset[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a75e0",
   "metadata": {},
   "source": [
    "### Print information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c866942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: cora()\n",
      "-------------------\n",
      "Number of graphs: 1\n",
      "Number of nodes: 2708\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n",
      "\n",
      "Graph:\n",
      "------\n",
      "Edges are directed: False\n",
      "Graph has isolated nodes: False\n",
      "Graph has loops: False\n"
     ]
    }
   ],
   "source": [
    "# Print information about the dataset\n",
    "print(f'Dataset: {dataset}')\n",
    "print('-------------------')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of nodes: {data.x.shape[0]}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "# Print information about the graph\n",
    "print(f'\\nGraph:')\n",
    "print('------')\n",
    "print(f'Edges are directed: {data.is_directed()}')\n",
    "print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Graph has loops: {data.has_self_loops()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45246e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of isolated nodes = 0\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import remove_isolated_nodes\n",
    "\n",
    "isolated = (remove_isolated_nodes(data['edge_index'])[2] == False).sum(dim=0).item()\n",
    "print(f'Number of isolated nodes = {isolated}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b67549f-b192-4222-814e-e67171abcae4",
   "metadata": {},
   "source": [
    "### 1. Extracting subgraphs from set of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50bcb3ac-c19c-4df6-bcc8-857c56941e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from torch_geometric.typing import OptTensor, PairTensor\n",
    "from torch_geometric.utils import scatter\n",
    "from torch_geometric.utils.map import map_index\n",
    "from torch_geometric.utils.mask import index_to_mask\n",
    "from torch_geometric.utils.num_nodes import maybe_num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d08ce0e5-52ce-4220-bf7b-7587568512b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Graph:\n",
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "\n",
      "Subgraph:\n",
      "(tensor([[1, 2],\n",
      "        [2, 1]]), None)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import subgraph\n",
    "\n",
    "# Load Cora dataset\n",
    "dataset = Planetoid(root='.', name='Cora', transform=T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "edge_index  = data.edge_index\n",
    "\n",
    "# Example: Extract subgraph for nodes 0, 1, 2, 3\n",
    "sampled_nodes = torch.tensor([0, 1, 2, 3])\n",
    "subgraph_data = subgraph(sampled_nodes, edge_index, edge_attr=None)\n",
    "\n",
    "print(\"Original Graph:\")\n",
    "print(data)\n",
    "\n",
    "print(\"\\nSubgraph:\")\n",
    "print(subgraph_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6127747d-4fd4-44e9-9eaa-2eadc7f29a5a",
   "metadata": {},
   "source": [
    "### 2. Extracting k_hop_subgraph from nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83c6b10d-d324-4d93-8daf-9ca6c57e152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#node_idx: The target node(s).\n",
    "#num_hops: The number of hops :math:`k`.\n",
    "#edge_index: The edge indices.\n",
    "def k_hop_subgraph(\n",
    "    node_idx: Union[int, List[int], Tensor],\n",
    "    num_hops: int,\n",
    "    edge_index: Tensor,\n",
    "    relabel_nodes: bool = False,\n",
    "    num_nodes: Optional[int] = None,\n",
    "    flow: str = 'source_to_target',\n",
    "    directed: bool = False,) -> Tuple[Tensor, Tensor, Tensor, Tensor]:\n",
    " \n",
    "    num_nodes = maybe_num_nodes(edge_index, num_nodes)\n",
    "\n",
    "    assert flow in ['source_to_target', 'target_to_source']\n",
    "    if flow == 'target_to_source':\n",
    "        row, col = edge_index\n",
    "    else:\n",
    "        col, row = edge_index\n",
    "\n",
    "    node_mask = row.new_empty(num_nodes, dtype=torch.bool)\n",
    "    edge_mask = row.new_empty(row.size(0), dtype=torch.bool)\n",
    "\n",
    "    if isinstance(node_idx, (int, list, tuple)):\n",
    "        node_idx = torch.tensor([node_idx], device=row.device).flatten()\n",
    "    else:\n",
    "        node_idx = node_idx.to(row.device)\n",
    "\n",
    "    subsets = [node_idx]\n",
    "\n",
    "    for _ in range(num_hops):\n",
    "        node_mask.fill_(False)\n",
    "        node_mask[subsets[-1]] = True\n",
    "        torch.index_select(node_mask, 0, row, out=edge_mask)\n",
    "        subsets.append(col[edge_mask])\n",
    "\n",
    "    subset, inv = torch.cat(subsets).unique(return_inverse=True)\n",
    "    inv = inv[:node_idx.numel()]\n",
    "\n",
    "    node_mask.fill_(False)\n",
    "    node_mask[subset] = True\n",
    "\n",
    "    if not directed:\n",
    "        edge_mask = node_mask[row] & node_mask[col]\n",
    "\n",
    "    edge_index = edge_index[:, edge_mask]\n",
    "\n",
    "    if relabel_nodes:\n",
    "        node_idx = row.new_full((num_nodes, ), -1)\n",
    "        node_idx[subset] = torch.arange(subset.size(0), device=row.device)\n",
    "        edge_index = node_idx[edge_index]\n",
    "\n",
    "    return subset, edge_index, inv, edge_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edc483a-f31f-440f-ad96-bd2cdc000988",
   "metadata": {},
   "source": [
    "#### Get subgraphs from target node 6 with 2 hops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "19799a3b-9220-4093-8f28-5ef27db3abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import subgraph\n",
    "\n",
    "# Load Cora dataset\n",
    "dataset = Planetoid(root='.', name='Cora', transform=T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "edge_index  = data.edge_index\n",
    "\n",
    "subset, edge_index, mapping, edge_mask = k_hop_subgraph(6, 2, edge_index, relabel_nodes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "920ea9de-6ae4-4aba-a8a5-38589d70faf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  0,  0,  1,  2,  3,  3,  3,  3,  3,  4,  4,  4,  4,  5,  6,  7,\n",
      "          8,  8,  9,  9,  9, 10, 11, 12, 13, 14, 14, 15, 15, 16, 16, 17, 17, 17,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "         17, 17, 18, 18, 19, 19, 19, 20, 21, 22, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "         23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 25, 26, 26, 27, 27, 27, 27,\n",
      "         27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 29, 29, 30, 30, 31, 32, 33, 33,\n",
      "         34, 34, 34, 34, 35, 35, 36, 36, 36, 37, 37, 37, 37, 38, 38, 38, 39, 40,\n",
      "         40, 40, 41, 41, 42, 42, 43, 43],\n",
      "        [ 9, 17, 23, 27, 23, 23, 17, 19, 23, 26, 36, 27, 28, 37, 41, 27, 23, 23,\n",
      "         27, 29,  0, 16, 17, 17, 23, 17, 23, 17, 40, 23, 30,  9, 17,  0,  3,  9,\n",
      "         10, 12, 14, 16, 18, 19, 20, 21, 25, 26, 28, 33, 34, 35, 36, 37, 38, 40,\n",
      "         42, 43, 17, 43,  3, 17, 23, 17, 17, 27,  0,  1,  2,  3,  6,  7, 11, 13,\n",
      "         15, 19, 24, 27, 29, 30, 31, 32, 33, 34, 23, 17,  3, 17,  0,  4,  5,  8,\n",
      "         22, 23, 37, 39, 40, 41,  4, 17, 37, 38,  8, 23, 15, 23, 23, 23, 17, 23,\n",
      "         17, 23, 35, 36, 17, 34,  3, 17, 34,  4, 17, 27, 28, 17, 28, 42, 27, 14,\n",
      "         17, 27,  4, 27, 17, 38, 17, 18]])\n"
     ]
    }
   ],
   "source": [
    "print(edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9889b8-fdc9-4db3-bce3-f3a791e63bc1",
   "metadata": {},
   "source": [
    "### 3. Drop a random walk path\n",
    "\n",
    "Drops edges from the adjacency matrix  based on random walks. The source nodes to start random walks from ar   sampled froedge index with probability p, following a Bernoulli distribution. on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7780c38b-7ab6-4cf7-856b-c36cf73ef4e3",
   "metadata": {},
   "source": [
    "#### Construct GCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b89afd27-86b3-4e41-996b-75ef376ecf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_dropout_path(torch.nn.Module):\n",
    "  \"\"\"Graph Convolutional Network\"\"\"\n",
    "  def __init__(self, dim_in, dim_h, dim_out):\n",
    "    super().__init__()\n",
    "    self.gcn1 = GCNConv(dim_in, dim_h)\n",
    "    self.gcn2 = GCNConv(dim_h, dim_out)\n",
    "    self.optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                      lr=0.01,\n",
    "                                      weight_decay=5e-4)\n",
    "\n",
    "  def forward(self, x, edge_index):\n",
    "    h = F.dropout(x, p=0.5, training=self.training)\n",
    "    h = self.gcn1(h, edge_index)\n",
    "    h = torch.relu(h)\n",
    "    h = F.dropout(h, p=0.5, training=self.training)\n",
    "    h = self.gcn2(h, edge_index)\n",
    "    return h, F.log_softmax(h, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463b545d-c159-4405-826e-b1e9b017ee42",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b7b3cce-5dc4-44f9-b7fb-c0ea5ab9ac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import dropout_path\n",
    "\n",
    "def train_dropout_path(model, data):\n",
    "    \"\"\"Train a GNN model and return the trained model.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = model.optimizer\n",
    "    epochs = 5\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs+1):\n",
    "        # Training\n",
    "        optimizer.zero_grad()\n",
    "        edge_index1, _ = dropout_path(data.edge_index, p= 0.2,walks_per_node = 1, walk_length = 3)\n",
    "        _, out = model(data.x, edge_index1 )\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "        val_acc = accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])\n",
    "\n",
    "        # Print metrics every 10 epochs\n",
    "        if(epoch % 1 == 0):\n",
    "            print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: '\n",
    "                  f'{acc*100:>6.2f}% | Val Loss: {val_loss:.2f} | '\n",
    "                  f'Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bce03819-1bb1-447e-aaf2-69e37d78385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred_y, y):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    return ((pred_y == y).sum() / len(y)).item()\n",
    "def test(model, data):\n",
    "    \"\"\"Evaluate the model on test set and print the accuracy score.\"\"\"\n",
    "    model.eval()\n",
    "    _, out = model(data.x, data.edge_index)\n",
    "    acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ef64126b-4707-4c8f-9815-64e89330edb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN_dropout_path(\n",
      "  (gcn1): GCNConv(1433, 16)\n",
      "  (gcn2): GCNConv(16, 7)\n",
      ")\n",
      "Epoch   0 | Train Loss: 1.945 | Train Acc:  16.43% | Val Loss: 1.94 | Val Acc: 19.00%\n",
      "Epoch   1 | Train Loss: 1.937 | Train Acc:  28.57% | Val Loss: 1.94 | Val Acc: 13.60%\n",
      "Epoch   2 | Train Loss: 1.931 | Train Acc:  33.57% | Val Loss: 1.94 | Val Acc: 20.60%\n",
      "Epoch   3 | Train Loss: 1.923 | Train Acc:  44.29% | Val Loss: 1.94 | Val Acc: 24.60%\n",
      "Epoch   4 | Train Loss: 1.916 | Train Acc:  40.00% | Val Loss: 1.93 | Val Acc: 30.40%\n",
      "Epoch   5 | Train Loss: 1.907 | Train Acc:  55.00% | Val Loss: 1.92 | Val Acc: 36.60%\n",
      "\n",
      "GCN test accuracy: 64.10%\n",
      "\n",
      "CPU times: total: 1.12 s\n",
      "Wall time: 139 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "from torch_geometric.nn import GCNConv\n",
    "# Create GCN model\n",
    "gcn_dropout_path = GCN_dropout_path(dataset.num_features, 16, dataset.num_classes).to(device)\n",
    "print(gcn_dropout_path)\n",
    "\n",
    "# Train\n",
    "train_dropout_path(gcn_dropout_path, data.to(device))\n",
    "\n",
    "# Test\n",
    "acc = test(gcn_dropout_path, data)\n",
    "print(f'\\nGCN test accuracy: {acc*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148a4732-99c8-41a1-a942-dcaa3e278633",
   "metadata": {},
   "source": [
    "### 4. MixHop Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1308236-a27a-4262-8776-fdb99ca8cbe7",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "774388cf-deb2-45e4-a525-c81f8a249ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import BatchNorm, Linear, MixHopConv\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "path = osp.join('.', 'data', 'Planetoid')\n",
    "dataset = Planetoid(path, name='Cora')\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d84509d-462b-4417-9310-d70433239b03",
   "metadata": {},
   "source": [
    "#### Class Mixhop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9bd17412-4f7e-4ed0-ac77-582b9866872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixHop(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = MixHopConv(dataset.num_features, 60, powers=[0, 1, 2])\n",
    "        self.norm1 = BatchNorm(3 * 60)\n",
    "\n",
    "        self.conv2 = MixHopConv(3 * 60, 60, powers=[0, 1, 2])\n",
    "        self.norm2 = BatchNorm(3 * 60)\n",
    "\n",
    "        self.conv3 = MixHopConv(3 * 60, 60, powers=[0, 1, 2])\n",
    "        self.norm3 = BatchNorm(3 * 60)\n",
    "\n",
    "        self.lin = Linear(3 * 60, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=0.7, training=self.training)\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.norm1(x)\n",
    "        x = F.dropout(x, p=0.9, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.norm2(x)\n",
    "        x = F.dropout(x, p=0.9, training=self.training)\n",
    "\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.norm3(x)\n",
    "        x = F.dropout(x, p=0.9, training=self.training)\n",
    "\n",
    "        return self.lin(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac35c4ea-757b-43b4-9387-731e23a8d9b9",
   "metadata": {},
   "source": [
    "#### Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "370c2de8-2f5c-4c19-9eb4-76c9b5a1cd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model, data = MixHop().to(device), data.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5, weight_decay=0.005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40,\n",
    "                                            gamma=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adfa7fb-41dc-40ef-8f39-3b97aae49b30",
   "metadata": {},
   "source": [
    "#### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c0e6294-8183-41b0-af93-6a2f2f173bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    return float(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829929e5-d533-4ed3-a976-f9c39fd15f48",
   "metadata": {},
   "source": [
    "#### Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b9a0026-9f4a-45e3-93ac-74cedce8923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    pred = model(data.x, data.edge_index).argmax(dim=-1)\n",
    "\n",
    "    accs = []\n",
    "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
    "        accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
    "    return accs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed4b954-4d31-4b6f-b903-9eb668968c93",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f1fcc481-c5f8-410b-86a3-4ab4e8fea6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 2.6880, Train: 0.2214, Val: 0.1520, Test: 0.1490\n",
      "Epoch: 002, Loss: 3.9377, Train: 0.2643, Val: 0.1780, Test: 0.2000\n",
      "Epoch: 003, Loss: 5.0827, Train: 0.4357, Val: 0.2620, Test: 0.2610\n",
      "Epoch: 004, Loss: 5.2836, Train: 0.3214, Val: 0.2620, Test: 0.2610\n",
      "Epoch: 005, Loss: 5.8246, Train: 0.3500, Val: 0.3400, Test: 0.3890\n",
      "Epoch: 006, Loss: 5.9115, Train: 0.4429, Val: 0.3920, Test: 0.3990\n",
      "Epoch: 007, Loss: 5.7034, Train: 0.5929, Val: 0.4700, Test: 0.4980\n",
      "Epoch: 008, Loss: 6.1699, Train: 0.5000, Val: 0.4700, Test: 0.4980\n",
      "Epoch: 009, Loss: 4.3237, Train: 0.5429, Val: 0.4700, Test: 0.4980\n",
      "Epoch: 010, Loss: 5.3870, Train: 0.5714, Val: 0.4700, Test: 0.4980\n",
      "Epoch: 011, Loss: 4.6217, Train: 0.6929, Val: 0.5480, Test: 0.5740\n",
      "Epoch: 012, Loss: 4.6847, Train: 0.5929, Val: 0.5480, Test: 0.5740\n",
      "Epoch: 013, Loss: 4.2669, Train: 0.8429, Val: 0.6880, Test: 0.7140\n",
      "Epoch: 014, Loss: 3.8027, Train: 0.8143, Val: 0.6880, Test: 0.7140\n",
      "Epoch: 015, Loss: 4.1063, Train: 0.8143, Val: 0.6880, Test: 0.7140\n",
      "Epoch: 016, Loss: 3.5333, Train: 0.7571, Val: 0.6880, Test: 0.7140\n",
      "Epoch: 017, Loss: 3.0016, Train: 0.7429, Val: 0.6880, Test: 0.7140\n",
      "Epoch: 018, Loss: 3.8960, Train: 0.7929, Val: 0.6880, Test: 0.7140\n",
      "Epoch: 019, Loss: 2.9892, Train: 0.8500, Val: 0.6880, Test: 0.7140\n",
      "Epoch: 020, Loss: 2.7297, Train: 0.8500, Val: 0.6880, Test: 0.7140\n",
      "Epoch: 021, Loss: 2.8616, Train: 0.9000, Val: 0.7060, Test: 0.7480\n",
      "Epoch: 022, Loss: 2.4412, Train: 0.8714, Val: 0.7060, Test: 0.7480\n",
      "Epoch: 023, Loss: 2.2244, Train: 0.8786, Val: 0.7060, Test: 0.7480\n",
      "Epoch: 024, Loss: 3.0684, Train: 0.8643, Val: 0.7060, Test: 0.7480\n",
      "Epoch: 025, Loss: 2.5912, Train: 0.8571, Val: 0.7060, Test: 0.7480\n",
      "Epoch: 026, Loss: 2.2095, Train: 0.8857, Val: 0.7120, Test: 0.7520\n",
      "Epoch: 027, Loss: 2.1274, Train: 0.8929, Val: 0.7260, Test: 0.7510\n",
      "Epoch: 028, Loss: 2.0680, Train: 0.8929, Val: 0.7260, Test: 0.7510\n",
      "Epoch: 029, Loss: 2.3681, Train: 0.8571, Val: 0.7260, Test: 0.7510\n",
      "Epoch: 030, Loss: 2.2705, Train: 0.8786, Val: 0.7260, Test: 0.7510\n",
      "Epoch: 031, Loss: 2.9195, Train: 0.9071, Val: 0.7440, Test: 0.7640\n",
      "Epoch: 032, Loss: 1.8645, Train: 0.9000, Val: 0.7440, Test: 0.7640\n",
      "Epoch: 033, Loss: 1.7379, Train: 0.8786, Val: 0.7440, Test: 0.7640\n",
      "Epoch: 034, Loss: 2.0947, Train: 0.9000, Val: 0.7500, Test: 0.7620\n",
      "Epoch: 035, Loss: 2.3529, Train: 0.8929, Val: 0.7500, Test: 0.7620\n",
      "Epoch: 036, Loss: 1.6892, Train: 0.9071, Val: 0.7500, Test: 0.7620\n",
      "Epoch: 037, Loss: 1.6400, Train: 0.9143, Val: 0.7520, Test: 0.7740\n",
      "Epoch: 038, Loss: 1.9907, Train: 0.9143, Val: 0.7520, Test: 0.7740\n",
      "Epoch: 039, Loss: 1.6891, Train: 0.9286, Val: 0.7580, Test: 0.7940\n",
      "Epoch: 040, Loss: 1.8049, Train: 0.9214, Val: 0.7580, Test: 0.7940\n",
      "Epoch: 041, Loss: 1.4335, Train: 0.9286, Val: 0.7580, Test: 0.7940\n",
      "Epoch: 042, Loss: 1.3944, Train: 0.9214, Val: 0.7580, Test: 0.7940\n",
      "Epoch: 043, Loss: 1.5219, Train: 0.9214, Val: 0.7600, Test: 0.7970\n",
      "Epoch: 044, Loss: 1.6394, Train: 0.9214, Val: 0.7600, Test: 0.7970\n",
      "Epoch: 045, Loss: 1.5371, Train: 0.9214, Val: 0.7600, Test: 0.7970\n",
      "Epoch: 046, Loss: 1.4965, Train: 0.9214, Val: 0.7620, Test: 0.7950\n",
      "Epoch: 047, Loss: 1.5721, Train: 0.9214, Val: 0.7640, Test: 0.7960\n",
      "Epoch: 048, Loss: 1.4883, Train: 0.9214, Val: 0.7660, Test: 0.7950\n",
      "Epoch: 049, Loss: 1.6846, Train: 0.9214, Val: 0.7660, Test: 0.7950\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = test_acc = 0\n",
    "for epoch in range(1, 50):\n",
    "    loss = train()\n",
    "    train_acc, val_acc, tmp_test_acc = test()\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        test_acc = tmp_test_acc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_acc:.4f}, '\n",
    "          f'Val: {best_val_acc:.4f}, Test: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8309d9-162d-4e1e-ad3c-ca3b38c4dfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
